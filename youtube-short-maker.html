<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Shorts Maker — Local & Free</title>
  <style>
    body{font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial;margin:18px;color:#111}
    h1{margin-bottom:6px}
    .row{display:flex;gap:12px;flex-wrap:wrap}
    .panel{border:1px solid #ddd;padding:12px;border-radius:8px;min-width:280px;flex:1}
    label{display:block;margin:8px 0 4px;font-weight:600}
    input[type=file]{padding:6px}
    input[type=range]{width:100%}
    button{padding:10px 14px;border-radius:8px;border:0;background:#0b76ff;color:#fff;cursor:pointer}
    button.secondary{background:#666}
    canvas{background:#000;display:block;margin:8px 0;max-width:100%}
    #log{white-space:pre-wrap;font-family:monospace;margin-top:8px;background:#f8f8f8;padding:8px;border-radius:6px}
    .small{font-size:13px;color:#555}
    textarea{width:100%;min-height:80px}
    .flex{display:flex;gap:8px;align-items:center}
  </style>
</head>
<body>
  <h1>Shorts Maker — Local & Free</h1>
  <div class="small">Upload a video, trim, center-crop to 9:16, add captions, then export a WebM short (video + original audio).</div>

  <div class="row" style="margin-top:12px">
    <div class="panel">
      <label>1) Upload video (mp4, webm...)</label>
      <input id="file" type="file" accept="video/*">
      <div id="video-info" class="small" style="margin-top:8px"></div>

      <label>2) Trim (seconds)</label>
      <div class="flex">
        <input id="startRange" type="range" min="0" max="1" step="0.01" value="0">
        <div id="startLabel" class="small">start: 0.00s</div>
      </div>
      <div class="flex">
        <input id="endRange" type="range" min="0" max="1" step="0.01" value="1">
        <div id="endLabel" class="small">end: 0.00s</div>
      </div>

      <label>3) Captions / Overlay text</label>
      <textarea id="captions" placeholder="Type the caption text that will be burned into the short (you can use multiple lines)."></textarea>

      <div style="display:flex;gap:8px;margin-top:8px">
        <button id="autoCropBtn">Auto Crop → 9:16 (preview)</button>
        <button id="clearBtn" class="secondary">Clear</button>
      </div>
    </div>

    <div class="panel">
      <label>Preview (canvas)</label>
      <canvas id="previewCanvas" width="720" height="1280"></canvas>

      <div style="display:flex;gap:8px;align-items:center;margin-top:8px">
        <button id="renderBtn">Render & Export WebM</button>
        <button id="pausePreview" class="secondary">Pause</button>
        <div id="downloadLinkArea"></div>
      </div>

      <div id="log"></div>
    </div>
  </div>

  <!-- hidden video element used as source -->
  <video id="sourceVideo" playsinline muted style="display:none"></video>

<script>
(async function(){
  const fileInput = document.getElementById('file');
  const video = document.getElementById('sourceVideo');
  const info = document.getElementById('video-info');
  const startRange = document.getElementById('startRange');
  const endRange = document.getElementById('endRange');
  const startLabel = document.getElementById('startLabel');
  const endLabel = document.getElementById('endLabel');
  const previewCanvas = document.getElementById('previewCanvas');
  const ctx = previewCanvas.getContext('2d');
  const autoCropBtn = document.getElementById('autoCropBtn');
  const renderBtn = document.getElementById('renderBtn');
  const clearBtn = document.getElementById('clearBtn');
  const captionsInput = document.getElementById('captions');
  const logEl = document.getElementById('log');
  const pauseBtn = document.getElementById('pausePreview');
  const downloadArea = document.getElementById('downloadLinkArea');

  let fileURL = null;
  let videoReady = false;
  let naturalWidth=0, naturalHeight=0;
  let playing = false;
  let autoCrop = true;

  function log(...args){ logEl.textContent = args.join(' ') }

  fileInput.addEventListener('change', (e)=>{
    if (fileURL) URL.revokeObjectURL(fileURL);
    const f = e.target.files[0];
    if (!f) return;
    fileURL = URL.createObjectURL(f);
    video.src = fileURL;
    video.load();
    videoReady = false;
    info.textContent = `Loaded file: ${f.name} — size ${Math.round(f.size/1024)} KB`;
    downloadArea.innerHTML = '';
    log('Loading video...')
  });

  video.addEventListener('loadedmetadata', ()=>{
    naturalWidth = video.videoWidth;
    naturalHeight = video.videoHeight;
    const dur = video.duration || 0.0;
    startRange.min = 0; startRange.max = dur; startRange.value = 0;
    endRange.min = 0; endRange.max = dur; endRange.value = dur;
    startRange.step = 0.01; endRange.step = 0.01;
    startLabel.textContent = `start: ${Number(startRange.value).toFixed(2)}s`;
    endLabel.textContent = `end: ${Number(endRange.value).toFixed(2)}s`;
    videoReady = true;
    log(`Video ready — ${naturalWidth}x${naturalHeight}, ${dur.toFixed(2)}s`);
  });

  startRange.addEventListener('input', ()=> {
    if (!videoReady) return;
    const s = Math.min(Number(startRange.value), Number(endRange.value)-0.05);
    startRange.value = s;
    startLabel.textContent = `start: ${Number(s).toFixed(2)}s`;
  });
  endRange.addEventListener('input', ()=> {
    if (!videoReady) return;
    const e = Math.max(Number(endRange.value), Number(startRange.value)+0.05);
    endRange.value = e;
    endLabel.textContent = `end: ${Number(e).toFixed(2)}s`;
  });

  autoCropBtn.addEventListener('click', ()=>{
    autoCrop = true;
    if (!videoReady) { log('Load a video first'); return; }
    // set canvas to portrait 9:16 but keep size reasonable
    previewCanvas.width = 720;
    previewCanvas.height = 1280;
    log('Canvas set to 720x1280 (9:16). Click Render to export.');
    // start preview playback
    startPreview();
  });

  clearBtn.addEventListener('click', ()=>{
    captionsInput.value = '';
    downloadArea.innerHTML = '';
    log('Cleared captions and previous output.');
  });

  pauseBtn.addEventListener('click', ()=>{
    if (playing){ stopPreview(); pauseBtn.textContent = 'Resume'; }
    else { startPreview(); pauseBtn.textContent = 'Pause'; }
  });

  function startPreview(){
    if (!videoReady) { log('Load a video first'); return; }
    // ensure canvas is 9:16
    if (previewCanvas.width / previewCanvas.height !== 9/16){
      previewCanvas.width = 720; previewCanvas.height = 1280;
    }

    video.currentTime = Number(startRange.value);
    video.muted = true;
    video.play().catch(()=>{});
    playing = true;
    requestAnimationFrame(drawLoop);
  }

  function stopPreview(){
    video.pause();
    playing = false;
  }

  function drawLoop(){
    if (!playing) return;
    const now = video.currentTime;
    const end = Number(endRange.value);
    if (now >= end){ video.pause(); playing = false; log('Preview ended'); return; }

    // draw center-cropped to fit canvas (9:16)
    const cw = previewCanvas.width, ch = previewCanvas.height;
    // desired source crop size to preserve aspect ratio
    const srcAR = video.videoWidth / video.videoHeight;
    const dstAR = cw / ch;

    let sx, sy, sw, sh;
    if (srcAR > dstAR){
      // source is wider => crop horizontally
      sh = video.videoHeight;
      sw = Math.round(sh * dstAR);
      sx = Math.round((video.videoWidth - sw) / 2);
      sy = 0;
    } else {
      // source is taller => crop vertically
      sw = video.videoWidth;
      sh = Math.round(sw / dstAR);
      sx = 0;
      sy = Math.round((video.videoHeight - sh) / 2);
    }

    // draw video frame cropped & scaled
    ctx.fillStyle = 'black';
    ctx.fillRect(0,0,cw,ch);
    try {
      ctx.drawImage(video, sx, sy, sw, sh, 0, 0, cw, ch);
    } catch (err) {
      // drawImage may throw if video not ready yet
    }

    // captions overlay
    const txt = captionsInput.value.trim();
    if (txt){
      const lines = txt.split('\n');
      const fontSize = Math.floor(cw/12);
      ctx.font = `bold ${fontSize}px system-ui, Arial`;
      ctx.textAlign = 'center';
      ctx.textBaseline = 'bottom';
      // shadow/background
      const padding = 12;
      const textBlockHeight = lines.length * (fontSize + 6) + padding*2;
      const blockY = ch - 40 - textBlockHeight;
      // translucent background
      ctx.fillStyle = 'rgba(0,0,0,0.45)';
      const blockX = cw*0.05;
      const blockW = cw*0.9;
      ctx.fillRect(blockX, blockY, blockW, textBlockHeight);
      ctx.fillStyle = 'white';
      for (let i=0;i<lines.length;i++){
        const line = lines[i];
        const y = blockY + padding + (i+1)*(fontSize + 6) - 6;
        ctx.fillText(line, cw/2, y);
      }
    }

    requestAnimationFrame(drawLoop);
  }

  // Main render/export
  renderBtn.addEventListener('click', async ()=>{
    if (!videoReady){ log('Please load a video file first.'); return; }
    renderBtn.disabled = true;
    log('Preparing render — this happens fully in your browser (no upload).');
    await doRender();
    renderBtn.disabled = false;
  });

  async function doRender(){
    // set canvas size 9:16 (use 720x1280 for speed)
    const cw = previewCanvas.width || 720;
    const ch = previewCanvas.height || 1280;
    previewCanvas.width = cw; previewCanvas.height = ch;

    // prepare drawing loop but controlled by playback
    // Create streams:
    // - canvasStream: the visual frames we draw
    // - audioTrack: from video.captureStream() (original audio)
    // We'll combine canvas video track + original audio track for recording

    // Ensure video unmuted to include audio in captureStream (some browsers require)
    video.muted = false;

    // Seek to start
    const start = Number(startRange.value);
    const end = Number(endRange.value);
    video.currentTime = start;

    // Wait for seeked
    await new Promise(res => {
      const t = setTimeout(res, 150);
      video.addEventListener('seeked', ()=>{
        clearTimeout(t); res();
      }, {once:true});
    });

    // Start video playback
    await video.play().catch(()=>{});

    // Setup canvas redraw tied to video frames
    let rafId = null;
    function drawFrame(){
      // crop logic same as preview
      const srcAR = video.videoWidth / video.videoHeight;
      const dstAR = cw / ch;
      let sx, sy, sw, sh;
      if (srcAR > dstAR){
        sh = video.videoHeight;
        sw = Math.round(sh * dstAR);
        sx = Math.round((video.videoWidth - sw) / 2);
        sy = 0;
      } else {
        sw = video.videoWidth;
        sh = Math.round(sw / dstAR);
        sx = 0;
        sy = Math.round((video.videoHeight - sh) / 2);
      }
      ctx.fillStyle = 'black';
      ctx.fillRect(0,0,cw,ch);
      try { ctx.drawImage(video, sx, sy, sw, sh, 0, 0, cw, ch); } catch(e){}
      // overlay captions
      const txt = captionsInput.value.trim();
      if (txt){
        const lines = txt.split('\n');
        const fontSize = Math.floor(cw/12);
        ctx.font = `bold ${fontSize}px system-ui, Arial`;
        ctx.textAlign = 'center';
        ctx.textBaseline = 'bottom';
        const padding = 12;
        const textBlockHeight = lines.length * (fontSize + 6) + padding*2;
        const blockY = ch - 40 - textBlockHeight;
        ctx.fillStyle = 'rgba(0,0,0,0.45)';
        const blockX = cw*0.05;
        const blockW = cw*0.9;
        ctx.fillRect(blockX, blockY, blockW, textBlockHeight);
        ctx.fillStyle = 'white';
        for (let i=0;i<lines.length;i++){
          const line = lines[i];
          const y = blockY + padding + (i+1)*(fontSize + 6) - 6;
          ctx.fillText(line, cw/2, y);
        }
      }
      // check end
      if (video.currentTime >= end){
        // stop drawing
        cancelAnimationFrame(rafId);
        return;
      }
      rafId = requestAnimationFrame(drawFrame);
    }
    rafId = requestAnimationFrame(drawFrame);

    // Get streams
    // Many browsers support HTMLMediaElement.captureStream() that includes audio track for media elements.
    const videoStream = video.captureStream ? video.captureStream() : null;
    if (!videoStream){
      log('Error: your browser does not support captureStream(). Use latest Chrome/Edge.');
      return;
    }

    // canvas stream (video only)
    const canvasStream = previewCanvas.captureStream(30); // 30fps
    const canvasVideoTrack = canvasStream.getVideoTracks()[0];
    // get audio tracks from video stream (original audio)
    const audioTracks = videoStream.getAudioTracks();
    if (!audioTracks || audioTracks.length === 0){
      log('Warning: source video has no audio track. Result will be silent.');
    }

    // combine
    const combined = new MediaStream();
    combined.addTrack(canvasVideoTrack);
    audioTracks.forEach(t => combined.addTrack(t));

    // MediaRecorder
    let recordedChunks = [];
    let mimeType = 'video/webm;codecs=vp8,opus';
    if (!MediaRecorder.isTypeSupported(mimeType)) {
      mimeType = 'video/webm';
    }
    const recorder = new MediaRecorder(combined, {mimeType});
    recorder.ondataavailable = (ev)=>{ if (ev.data && ev.data.size) recordedChunks.push(ev.data); };
    recorder.onstop = ()=>{
      const blob = new Blob(recordedChunks, {type: mimeType});
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = `short_${Math.floor(Date.now()/1000)}.webm`;
      a.textContent = 'Download short.webm';
      a.style.display = 'inline-block';
      a.style.padding = '8px';
      a.style.background = '#0b76ff';
      a.style.color = 'white';
      a.style.borderRadius = '6px';
      downloadArea.innerHTML = '';
      downloadArea.appendChild(a);
      log('Render complete — click download link.');
      // stop video playback
      video.pause();
    };

    // start recording
    recordedChunks = [];
    recorder.start(200); // gather every 200ms
    log('Recording started...');
    // play until end
    function waitUntilEnd(){
      return new Promise(resolve=>{
        const onTime = ()=>{
          if (video.currentTime >= end || video.ended){
            video.removeEventListener('timeupdate', onTime);
            resolve();
          }
        };
        video.addEventListener('timeupdate', onTime);
      });
    }
    await waitUntilEnd();
    // stop recorder after a small timeout to capture final frames
    await new Promise(r=> setTimeout(r, 250));
    recorder.stop();
    // allow onstop to fire
  }

})();
</script>
</body>
</html>
